#!/usr/bin/env python3

import argparse
import datetime
import ansible_runner
import os

from benchmark import Benchmark
from report import PrometheusMetricsReporter

class CommandLineTool:
    def __init__(self):
        self.parser = argparse.ArgumentParser(description="Toolkit for benchmarking the geospatial processing workload")
        self.parser.add_argument('-i', '--inventory', type=str, help='Inventory file', default='inventory.yml')
        self.subparsers = self.parser.add_subparsers(dest="command")

        # Create subparsers for "test" command
        self.test_parser = self.subparsers.add_parser("test", help='Manage the benchmarking tests')
        self.run_subparsers = self.test_parser.add_subparsers(dest="subcommand")
        # Subparser for the 'test run <scenario> <id>' subcommand
        self.run_parser = self.run_subparsers.add_parser('run', help='Run the benchmarking test. test run <scenario_name> <scenario_path> ')
        self.run_parser.add_argument('-n','--name', type=str, help='The scenario unique name identifier')
        self.run_parser.add_argument('-i','--input-dir', type=str, help='Path of input directory in local computer')
        self.run_parser.add_argument('-f', '--file', type=str, help='Scenario file name. The file can be in the form of shell script, QGIS json, or QGIS python. This file will be placed in similar directory with the input.')
        self.run_parser.add_argument('-r', '--repeat', type=int, help='The number of execution repeat', default=1)
        self.run_parser.add_argument('-c', '--converge', type=int, help='The number of converging percentage (in percent)', default=10)
        # Subparser for the 'test report' subcommand
        self.run_parser = self.run_subparsers.add_parser('report', help='Generate report for a benchmarking scenario')
        self.run_parser.add_argument('-n','--name', type=str, help='The scenario unique name identifier')
        # Subparser for the 'test list' subcommand
        self.run_parser = self.run_subparsers.add_parser('list', help='List all benchmarking scenario')
        # Subparser for the 'test remove <id>' subcommand
        self.run_parser = self.run_subparsers.add_parser('remove', help='Delete benchmarking scenario given the scenario id')
        self.run_parser.add_argument('id', type=str, help='The scenario id')
        # Subparser for the 'test save <id>' subcommand
        self.run_parser = self.run_subparsers.add_parser('save', help='Save benchmarking scenario to a specific local folder given the scenario id')
        self.run_parser.add_argument('id', type=str, help='The scenario id')
        # Subparser for the 'test save <id>' subcommand
        self.run_parser = self.run_subparsers.add_parser('inspect', help='Show benchmarking report result given the scenario id')
        self.run_parser.add_argument('id', type=str, help='The scenario id')
        # Subparser for the 'test display <id>' subcommand
        self.run_parser = self.run_subparsers.add_parser('display', help='Open Grafana dashboard given the scenario id')
        self.run_parser.add_argument('id', type=str, help='The scenario id')

        # Create subparsers for "snapshot" command
        self.snapshot_parser = self.subparsers.add_parser("snapshot", help='Manage snapshot')
        self.snapshot_subparsers = self.snapshot_parser.add_subparsers(dest="subsubcommand")
        # Subparser for the 'snapshot list' subcommand
        self.snapshot_parser = self.snapshot_subparsers.add_parser('list', help='List all snapshots')
        # Subparser for the 'snapshot remove <id>' subcommand
        self.snapshot_parser = self.snapshot_subparsers.add_parser('remove', help='Delete snapshot given the snapshot id')
        self.snapshot_parser.add_argument('id', type=str, help='The snapshot id')
        # Subparser for the 'snapshot save <id>' subcommand
        self.snapshot_parser = self.snapshot_subparsers.add_parser('save', help='Save snapshot to a specific local folder given the scenario id')
        self.snapshot_parser.add_argument('id', type=str, help='The snapshot id')
        # Subparser for the 'snapshot inspect <id>' subcommand
        self.snapshot_parser = self.snapshot_subparsers.add_parser('inspect', help='Show snapshot given the scenario id')
        self.snapshot_parser.add_argument('id', type=str, help='The snapshot id')

        # Create subparsers for "install" command
        self.snapshot_parser = self.subparsers.add_parser("install", help='Install required packages')
        

    def run(self):
        args = self.parser.parse_args()
        inventory_path = os.path.abspath(args.inventory)
        
        if args.command == 'test':
            #print(args)
            self.handle_test(args, inventory_path)
        elif args.command == 'snapshot':
            self.handle_snapshot(args, inventory_path)
        elif args.command == 'install':
            self.handle_install(args, inventory_path)
        else:
            self.parser.print_help()

    def handle_test(self, args, inventory_path):
        if args.subcommand == "run":
            # Get the input directory
            input_dir = os.path.abspath(args.input_dir)
            # Get the repetition parameter
            repeat = args.repeat
            # Get the script file name
            script_file = args.file
            # Get scenario name 
            scenario_name = args.name
            
            benchmark = Benchmark()
            benchmark.run(test_name=scenario_name, script_file=script_file, input_dir=input_dir, repeat=repeat, inventory_path=inventory_path)
            print(args.subcommand)
        elif args.subcommand == "list":
            benchmark = Benchmark()
            benchmark.list_all_results()
        elif args.subcommand == "report":
            # Get scenario name
            scenario_name = args.name
            benchmark = Benchmark()
            instance = benchmark.get_test_instance(scenario_name)
            if instance is not None:
                test_name  = instance["test_name"]
                # start_time = datetime.datetime.fromtimestamp(instance["start_time"])
                # end_time = datetime.datetime.fromtimestamp(instance["end_time"])
                end_time = datetime.datetime.now()
                start_time = end_time - datetime.timedelta(hours=1)
                reporter = PrometheusMetricsReporter(url="http://3.66.166.68:9090", disable_ssl=True)
                reporter.generate_report(start_time=start_time, end_time=end_time, test_name=test_name)
        else:
            self.parser.print_help()
    
    def handle_snapshot(self, args, inventory_path):
        print(args.subcommand)
        #print(f"{args.greet}, {args.name}!")

    def handle_install(self, args, inventory_path):
        r = ansible_runner.interface.run(
                private_data_dir = 'ansible' ,
                playbook='install.yml',
                inventory=inventory_path
            )



if __name__ == "__main__":
    tool = CommandLineTool()
    tool.run()
